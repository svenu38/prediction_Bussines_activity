{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suffix prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i ../script/requirements.py\n",
    "%run -i ../script/requirements_dll.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../df_completed_order.csv', dtype = {'_CASE_KEY' : str, 'WERKS' : str, 'EBELN' : str, 'EBELP': str, 'ACTIVITY_EN': str, '_SORTING' : int, 'USER_NAME': str})\n",
    "df['EVENTTIME'] = pd.to_datetime(df['EVENTTIME'])\n",
    "df = df.rename(columns={'_CASE_KEY' : 'case:concept:name',\n",
    "                       'ACTIVITY_EN' : 'concept:name',\n",
    "                       'EVENTTIME' : 'time:timestamp'})\n",
    "df.loc[df['RKDST'].isnull(), 'RKDST'] = 0\n",
    "df.loc[df['RKDST'] == 'x', 'RKDST'] = 1\n",
    "df.loc[df['MAVPR'].isnull(), 'MAVPR'] = 0\n",
    "df.loc[df['THWMS'].isnull(), 'THWMS'] = 0\n",
    "df.loc[df['LATEP'].isnull(), 'LATEP'] = 0\n",
    "df['MAVPR'] = df['MAVPR'].astype(int)\n",
    "df['THWMS'] = df['THWMS'].astype(int)\n",
    "df['LATEP'] = df['LATEP'].astype(int)\n",
    "\n",
    "sc_sorting = StandardScaler()\n",
    "df['_SORTING'] = sc_sorting.fit_transform(np.array(df['_SORTING']).reshape(-1, 1))\n",
    "df = df.sort_values(by = ['WERKS', 'EBELN', 'EBELP'])\n",
    "\n",
    "df = df.loc[df['concept:name'] != 'Late Shipment'].sort_values(by = ['WERKS','EBELN', 'EBELP', 'time:timestamp', '_SORTING'])\n",
    "df = df.loc[df['concept:name'] != 'Late Delivery'].sort_values(by = ['WERKS','EBELN', 'EBELP', 'time:timestamp', '_SORTING'])\n",
    "df = df.loc[df['concept:name'] != 'Due Date passed'].sort_values(by = ['WERKS','EBELN', 'EBELP', 'time:timestamp', '_SORTING'])\n",
    "#df = df.drop(columns=['ELIKZ'])\n",
    "df = df.reset_index(drop= True)\n",
    "\n",
    "n_act, onehot_encoder_act = one_hot_column(df['concept:name'])\n",
    "n_wer, onehot_encoder_wer = one_hot_column(df['WERKS'])\n",
    "n_nam, onehot_encoder_nam = one_hot_column(df['NAME1'])\n",
    "n_mag, onehot_encoder_mag = one_hot_column(df['MATKL'])\n",
    "n_mat, onehot_encoder_mat = one_hot_column(df['MATNR'])\n",
    "\n",
    "# Time\n",
    "A = [d.date() for d in df['time:timestamp']]\n",
    "B = [d.date() for d in df['time:timestamp'].shift(-1)]\n",
    "B[-1] = B[-2]\n",
    "df['time:diff'] = np.busday_count(A, B)\n",
    "df['time:diff'] = df['time:diff'].shift(1)\n",
    "df.loc[0, 'time:diff'] = 0\n",
    "idx = df.reset_index().groupby('case:concept:name')['index'].first().values\n",
    "df.loc[df.index.isin(idx), 'time:diff'] = 0\n",
    "sc = StandardScaler()\n",
    "df['time:diff'] = sc.fit_transform(np.array(df['time:diff']).reshape(-1, 1))\n",
    "df['concept:name'] = df.groupby('case:concept:name')['concept:name'].transform(lambda x: ','.join(x))\n",
    "df['time:diff'] = df['time:diff'].astype(str)\n",
    "df['time:diff'] = df.groupby('case:concept:name')['time:diff'].transform(lambda x: ','.join(x))\n",
    "df['_SORTING'] = df['_SORTING'].astype(str)\n",
    "df['_SORTING'] = df.groupby('case:concept:name')['_SORTING'].transform(lambda x: ','.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../df_incompleted_order.csv', dtype = {'_CASE_KEY' : str, 'WERKS' : str, 'EBELN' : str, 'EBELP': str, 'ACTIVITY_EN': str, '_SORTING' : int, 'USER_NAME': str})\n",
    "df['EVENTTIME'] = pd.to_datetime(df['EVENTTIME'])\n",
    "df = df.rename(columns={'_CASE_KEY' : 'case:concept:name',\n",
    "                       'ACTIVITY_EN' : 'concept:name',\n",
    "                       'EVENTTIME' : 'time:timestamp'})\n",
    "df.loc[df['RKDST'].isnull(), 'RKDST'] = 0\n",
    "df.loc[df['RKDST'] == 'x', 'RKDST'] = 1\n",
    "df.loc[df['MAVPR'].isnull(), 'MAVPR'] = 0\n",
    "df.loc[df['THWMS'].isnull(), 'THWMS'] = 0\n",
    "df.loc[df['LATEP'].isnull(), 'LATEP'] = 0\n",
    "df['MAVPR'] = df['MAVPR'].astype(int)\n",
    "df['THWMS'] = df['THWMS'].astype(int)\n",
    "df['LATEP'] = df['LATEP'].astype(int)\n",
    "\n",
    "df['_SORTING'] = sc_sorting.transform(np.array(df['_SORTING']).reshape(-1, 1))\n",
    "df = df.sort_values(by = ['WERKS', 'EBELN', 'EBELP'])\n",
    "\n",
    "df = df.loc[df['concept:name'] != 'Late Shipment'].sort_values(by = ['WERKS','EBELN', 'EBELP', 'time:timestamp', '_SORTING'])\n",
    "df = df.loc[df['concept:name'] != 'Late Delivery'].sort_values(by = ['WERKS','EBELN', 'EBELP', 'time:timestamp', '_SORTING'])\n",
    "df = df.loc[df['concept:name'] != 'Due Date passed'].sort_values(by = ['WERKS','EBELN', 'EBELP', 'time:timestamp', '_SORTING'])\n",
    "df = df.reset_index(drop= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_timestamp = np.array(df.groupby(['case:concept:name'])['time:timestamp'].last())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Time\n",
    "A = [d.date() for d in df['time:timestamp']]\n",
    "B = [d.date() for d in df['time:timestamp'].shift(-1)]\n",
    "B[-1] = B[-2]\n",
    "df['time:diff'] = np.busday_count(A, B)\n",
    "df['time:diff'] = df['time:diff'].shift(1)\n",
    "df.loc[0, 'time:diff'] = 0\n",
    "idx = df.reset_index().groupby('case:concept:name')['index'].first().values\n",
    "df.loc[df.index.isin(idx), 'time:diff'] = 0\n",
    "df['time:diff'] = sc.transform(np.array(df['time:diff']).reshape(-1, 1))\n",
    "df['concept:name'] = df.groupby('case:concept:name')['concept:name'].transform(lambda x: ','.join(x))\n",
    "df['time:diff'] = df['time:diff'].astype(str)\n",
    "df['time:diff'] = df.groupby('case:concept:name')['time:diff'].transform(lambda x: ','.join(x))\n",
    "df['_SORTING'] = df['_SORTING'].astype(str)\n",
    "df['_SORTING'] = df.groupby('case:concept:name')['_SORTING'].transform(lambda x: ','.join(x))\n",
    "\n",
    "df = df[['case:concept:name', 'concept:name', 'RKDST', 'WERKS', 'time:diff', 'NAME1', 'MATKL', 'MATNR', 'MAVPR', 'THWMS', 'LATES','LATED','LATEP', '_SORTING']].drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "traces= []\n",
    "diff_time = []\n",
    "sorting = []\n",
    "for q in range(len(df)):\n",
    "    string = np.array(df.loc[q, 'concept:name'].split(','),dtype = str).reshape(-1,1)\n",
    "    onehot_encoded = onehot_encoder_act.transform(string)\n",
    "    traces.append(onehot_encoded)\n",
    "    diff_time.append(np.array(df.loc[q, 'time:diff'].split(','),dtype = float))\n",
    "    sorting.append(np.array(df.loc[q, '_SORTING'].split(','),dtype = float))\n",
    "print('Traccie: ',len(traces))\n",
    "\n",
    "rda = df['RKDST']\n",
    "werks_bef = df['WERKS']\n",
    "name1_bef = df['NAME1']\n",
    "matkl_bef = df['MATKL']\n",
    "matnr_bef = df['MATNR']\n",
    "mavp = df['MAVPR']\n",
    "twms = df['THWMS']\n",
    "lates = df['LATES']\n",
    "lated = df['LATED']\n",
    "latep = df['LATEP']\n",
    "\n",
    "werks = onehot_encoder_wer.transform(np.array(werks_bef).reshape(-1, 1))\n",
    "name1 = onehot_encoder_nam.transform(np.array(name1_bef).reshape(-1, 1))\n",
    "matkl = onehot_encoder_mag.transform(np.array(matkl_bef).reshape(-1, 1))\n",
    "matnr = onehot_encoder_mat.transform(np.array(matnr_bef).reshape(-1, 1))\n",
    "\n",
    "## RDA\n",
    "for l in range(len(traces)):\n",
    "    to_app = np.array([[rda[l]] * len(traces[l])]).reshape(len(traces[l]), 1)\n",
    "    traces[l] = np.append(traces[l], to_app, axis = 1)\n",
    "# WERKS\n",
    "for l in range(len(traces)):\n",
    "    to_app = np.array([[werks[l]] * len(traces[l])]).reshape(len(traces[l]), n_wer)\n",
    "    traces[l] = np.append(traces[l], to_app, axis = 1)\n",
    "# NAME1\n",
    "for l in range(len(traces)):\n",
    "    to_app = np.array([[name1[l]] * len(traces[l])]).reshape(len(traces[l]), n_nam)\n",
    "    traces[l] = np.append(traces[l], to_app, axis = 1)\n",
    "# MATKL\n",
    "for l in range(len(traces)):\n",
    "    to_app = np.array([[matkl[l]] * len(traces[l])]).reshape(len(traces[l]), n_mag)\n",
    "    traces[l] = np.append(traces[l], to_app, axis = 1)\n",
    "# MATNR\n",
    "for l in range(len(traces)):\n",
    "    to_app = np.array([[matnr[l]] * len(traces[l])]).reshape(len(traces[l]), n_mat)\n",
    "    traces[l] = np.append(traces[l], to_app, axis = 1)\n",
    "# TIME\n",
    "for l in range(len(traces)):\n",
    "    to_app = diff_time[l].reshape(len(traces[l]),1)\n",
    "    traces[l] = np.append(traces[l], to_app, axis = 1)\n",
    "# MAVP\n",
    "for l in range(len(traces)):\n",
    "    to_app = np.array([[mavp[l]] * len(traces[l])]).reshape(len(traces[l]), 1)\n",
    "    traces[l] = np.append(traces[l], to_app, axis = 1)\n",
    "# TWMS\n",
    "for l in range(len(traces)):\n",
    "    to_app = np.array([[twms[l]] * len(traces[l])]).reshape(len(traces[l]), 1)\n",
    "    traces[l] = np.append(traces[l], to_app, axis = 1)\n",
    "# LATES\n",
    "for l in range(len(traces)):\n",
    "    to_app = np.array([[lates[l]] * len(traces[l])]).reshape(len(traces[l]), 1)\n",
    "    traces[l] = np.append(traces[l], to_app, axis = 1)\n",
    "# LATED\n",
    "for l in range(len(traces)):\n",
    "    to_app = np.array([[lated[l]] * len(traces[l])]).reshape(len(traces[l]), 1)\n",
    "    traces[l] = np.append(traces[l], to_app, axis = 1)\n",
    "# LATEP\n",
    "for l in range(len(traces)):\n",
    "    to_app = np.array([[latep[l]] * len(traces[l])]).reshape(len(traces[l]), 1)\n",
    "    traces[l] = np.append(traces[l], to_app, axis = 1)\n",
    "# # SORTING\n",
    "# for l in range(len(traces)):\n",
    "#     to_app = sorting[l].reshape(len(traces[l]),1)\n",
    "#     traces[l] = np.append(traces[l], to_app, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL TRACES\n",
    "n_zero = traces[0].shape[1]\n",
    "\n",
    "X = traces.copy()\n",
    "\n",
    "max_trace = 15\n",
    "\n",
    "for i in range(len(X)):\n",
    "    num = max_trace - len(X[i])\n",
    "    for n in range(num):\n",
    "        X[i] = np.append(X[i], [[0] * n_zero],  axis=0)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rda_train = X[:,0,n_act].reshape(-1,1)\n",
    "X_wer_train = X[:,0,n_act+1 : n_act+1+n_wer]\n",
    "X_nam_train = X[:,0,n_act+1+n_wer : n_act+1+n_wer+n_nam]\n",
    "X_mag_train = X[:,0,n_act+1+n_wer+n_nam : n_act+1+n_wer+n_nam+n_mag]\n",
    "X_mat_train = X[:,0,n_act+1+n_wer+n_nam+n_mag : n_act+1+n_wer+n_nam+n_mag+n_mat]\n",
    "X_time_train = X[:,:, n_act+1+n_wer+n_nam+n_mag+n_mat].reshape(-1,max_trace,1)\n",
    "X_train = X[:,:,:n_act]\n",
    "\n",
    "class_weights = np.load('class_weights.npy')\n",
    "loss = weighted_categorical_crossentropy(class_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model/model_suffix_act_2.h5', custom_objects = {'loss' : loss})\n",
    "model.summary()\n",
    "\n",
    "model_time = keras.models.load_model('model/model_suffix_time.h5', custom_objects = {'loss' : loss})\n",
    "model.summary()\n",
    "\n",
    "suffix = X_train.copy()\n",
    "suffix_time = X_time_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in range(len(suffix)):\n",
    "    for i in range(len(suffix[q])):\n",
    "\n",
    "        yhat, yhat_mavp = model.predict([\n",
    "            suffix[q].reshape(1, suffix[q].shape[0], suffix[q].shape[1]),\n",
    "            suffix_time[q].reshape(1, suffix_time[q].shape[0], suffix_time[q].shape[1]),\n",
    "            X_rda_train[q].reshape(1, X_rda_train[q].shape[0]),\n",
    "            X_wer_train[q].reshape(1, X_wer_train[q].shape[0]),\n",
    "            X_nam_train[q].reshape(1, X_nam_train[q].shape[0]),\n",
    "            X_mag_train[q].reshape(1, X_mag_train[q].shape[0]),\n",
    "            X_mat_train[q].reshape(1, X_mat_train[q].shape[0])\n",
    "                                        ])\n",
    "\n",
    "        for c in range(max_trace):\n",
    "            if (suffix[q][c] == [0] * n_act).all():\n",
    "                act = np.random.choice(np.arange(0,15), p = yhat[0])\n",
    "                suffix[q][c][act] = 1\n",
    "                yhat_time = model_time.predict([\n",
    "                                                suffix[q].reshape(1, suffix[q].shape[0], suffix[q].shape[1]),\n",
    "                                                suffix_time[q].reshape(1, suffix_time[q].shape[0], suffix_time[q].shape[1]),\n",
    "                                                X_rda_train[q].reshape(1, X_rda_train[q].shape[0]),\n",
    "                                                #X_wer_train[q].reshape(1, X_wer_train[q].shape[0]),\n",
    "                                                #X_nam_train[q].reshape(1, X_nam_train[q].shape[0]),\n",
    "                                                X_mag_train[q].reshape(1, X_mag_train[q].shape[0]),\n",
    "                                                #X_mat_train[q].reshape(1, X_mat_train[q].shape[0])\n",
    "                                        ])\n",
    "                suffix_time[q][c] = yhat_time\n",
    "                break\n",
    "        if act == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_list = []\n",
    "for i in range(len(suffix)):\n",
    "    suffix_list.append(suffix[i][~np.all(suffix[i]==X_train[i], axis=1)])\n",
    "\n",
    "suffix_time_list = []\n",
    "for i in range(len(suffix_time)):\n",
    "    suffix_time_list.append(suffix_time[i][~np.all(suffix_time[i]==X_time_train[i], axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_activity = []\n",
    "for i in range(len(suffix_list)):\n",
    "    suffix_activity.append(onehot_encoder_act.inverse_transform(suffix_list[i]).reshape(-1).tolist())\n",
    "\n",
    "suffix_time_df = []\n",
    "for i in range(len(suffix_time_list)):\n",
    "    suffix_time_df.append(sc.inverse_transform(suffix_time_list[i]).reshape(-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sum(suffix_time_df, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = dict(zip(df['case:concept:name'], suffix_activity))\n",
    "dictionary_time = dict(zip(df['case:concept:name'], suffix_time_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(suffix_time_df[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timestamp_activity = []\n",
    "for i in range(len(suffix_time_df)):\n",
    "    for j in range(len(suffix_time_df[i])):\n",
    "        last_timestamp[i] = last_timestamp[i] + np.timedelta64(int(suffix_time_df[i][j]), 'D')\n",
    "        timestamp_activity.append(last_timestamp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_suffix = pd.DataFrame.from_dict(dictionary, orient='index').stack().reset_index()[['level_0', 0]]\n",
    "\n",
    "df_suffix = df_suffix.rename(columns={\"level_0\": \"case:concept:name\", 0: \"Activity\"})\n",
    "df_suffix['WERKS'] = df_suffix['case:concept:name'].str[:4]\n",
    "df_suffix['EBELN'] = df_suffix['case:concept:name'].str[4:10]\n",
    "df_suffix['EBELP'] = df_suffix['case:concept:name'].str[10:]\n",
    "df_suffix['timestamp'] = timestamp_activity\n",
    "df_suffix['timestamp'] = df_suffix['timestamp'].map(dates_business)\n",
    "df_suffix['_CASE_KEY'] = df_suffix['WERKS'] + '-' + df_suffix['EBELN'] + '-' + df_suffix['EBELP']\n",
    "df_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pool.create_table(df=df_suffix, table_name=\"ANOM\", drop_if_exists=True, force = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = sc.inverse_transform(yhat_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anom = pd.DataFrame({'Maverick Purchase': np.round(yhat_mavp * 100, 1).reshape(-1)})\n",
    "# df_lates = pd.DataFrame(np.round(yhat_lates), columns = ['Next activity time (days)'])\n",
    "df_anom = df_anom.astype(float).round(2)\n",
    "df_anom['WERKS'] = df['case:concept:name'].str[:4]\n",
    "df_anom['EBELN'] = df['case:concept:name'].str[5:12]\n",
    "df_anom['EBELP'] = df['case:concept:name'].str[13:]\n",
    "df_anom = df_anom[['WERKS', 'EBELN', 'EBELP', 'Maverick Purchase' , '3-Way-Mismatch', 'Late Shipment' ,'Late Delivery', 'Late Payment' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anom = pd.DataFrame({'Maverick Purchase': np.round(yhat_mavp * 100, 1).reshape(-1),\n",
    "                        '3-Way-Mismatch': np.round(yhat_twm * 100, 1).reshape(-1),\n",
    "                        'Late Shipment': np.round(yhat_lates * 100, 1).reshape(-1),\n",
    "                        'Late Delivery': np.round(yhat_lated * 100, 1).reshape(-1),\n",
    "                        'Late Payment': np.round(yhat_latep* 100, 1).reshape(-1),\n",
    "                        })\n",
    "# df_lates = pd.DataFrame(np.round(yhat_lates), columns = ['Next activity time (days)'])\n",
    "df_anom = df_anom.astype(float).round(2)\n",
    "df_anom['WERKS'] = df['case:concept:name'].str[:4]\n",
    "df_anom['EBELN'] = df['case:concept:name'].str[5:12]\n",
    "df_anom['EBELP'] = df['case:concept:name'].str[13:]\n",
    "df_anom = df_anom[['WERKS', 'EBELN', 'EBELP', 'Maverick Purchase' , '3-Way-Mismatch', 'Late Shipment' ,'Late Delivery', 'Late Payment' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_act = pd.DataFrame(np.round(yhat * 100, 1), columns = onehot_encoder_act.inverse_transform(np.identity(n_act))[:,0])\n",
    "df_time = pd.DataFrame(np.round(days), columns = ['Next activity time (days)'])\n",
    "df_pred = df_act.join(df_time).astype(float).round(2)\n",
    "df_pred['WERKS'] = df['case:concept:name'].str[:4]\n",
    "df_pred['EBELN'] = df['case:concept:name'].str[5:12]\n",
    "df_pred['EBELP'] = df['case:concept:name'].str[13:]\n",
    "df_pred = df_pred[['WERKS', 'EBELN', 'EBELP', 'Next activity time (days)', 'Change Price', 'Change Quantity',\n",
    "       'Purchase Requisition Item: Rejected', 'Purchase Order Item: Rejected', 'Set Payment Block' ]]\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pool.create_table(df=df_pred, table_name=\"PRED\", drop_if_exists=True, force = True)\n",
    "data_pool.create_table(df=df_anom, table_name=\"ANOM\", drop_if_exists=True, force = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
